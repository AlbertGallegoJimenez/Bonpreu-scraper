# Bonpreu-scraper
[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.14036298.svg.svg)](https://doi.org/10.5281/zenodo.14036298)


## DescripciÃ³n del repositorio

Este repositorio contiene el cÃ³digo para realizar _web scraping_ para obtener datos de productos a la venta en la empresa de alimentaciÃ³n BonpreuEsclat.

<div align="center">
      <img src="image.png" width="50%">
</div>

El producto final de este proyecto se almacena en la carpeta [data](/data) en formato CSV, que incluye informaciÃ³n detallada sobre los productos en venta.
<br>Para obtener mÃ¡s informaciÃ³n sobre el enfoque metodolÃ³gico utilizado, la estructura del conjunto de datos resultante y otros detalles relevantes, consulta la documentaciÃ³n disponible en la carpeta [docs](/docs).

Este proyecto se presenta como la PrÃ¡ctica 1 de la asignatura M2.851 - TipologÃ­a y Ciclo de Vida de los Datos del MÃ¡ster de Data Science de la UOC.

## Estructura del repositorio

- ğŸ“‚ [**data**](/data): Carpeta con datos obtenidos de la prÃ¡ctica.
  - ğŸ“„[**bonpreu_products_20241104_173704.csv**](/data/bonpreu_products_20241104_173704.csv): Dataset resultante de ejecutar el programa.
- ğŸ“‚ [**docs**](/docs): Carpeta con archivos de documentaciÃ³n.
  - ğŸ“[**PR1_Memoria_Roldan_Gallego.pdf**](/src/main.py): Memoria de la prÃ¡ctica.
- ğŸ“‚ [**src**](/src): Carpeta con el cÃ³digo fuente.
  - ğŸ“„[**main.py**](/src/main.py): Script principal para ejecutar el scraper.
  - ğŸ“„[**scraper.py**](/src/scraper.py): Define la clase ``BonpreuScraper`` con las funciones principales de scraping.
  - ğŸ“„[**merge_csv.py**](/src/merge_csv.py): Script que automatiza la fusiÃ³n de los CSVs exportados por categorÃ­as en un solo archivo CSV llamado ``bonpreu_products_YYYYmmdd_HHMMSS.csv``.
- ğŸ“‚ [**tests**](/tests): Pruebas automatizados.
  - ğŸ“„[**test_scraper.py**](/tests/test_scraper.py): Script que contiene varias pruebas unitarias del scraper. 
- ğŸ“„ **environment.yml**: Archivo YML para instalar un environment de Anaconda igual que el usado para el desarrollo del proyecto.
- ğŸ–¼ï¸ **imagen.png**: Imagen que contiene el logo de BonpreuEsclat.
- ğŸ“„ **LICENSE**: Archivo de licencia.
- ğŸ“„ **requirements.txt**: Un archivo de requirements donde se detallan las librerÃ­as utilizadas con sus respectivas versiones.
- ğŸ“„ **README.md**: Este mismo archivo README.

## InstalaciÃ³n

0. Si usas [Anaconda](https://www.anaconda.com/) puedes crear un **environment** directamente desde el archivo **environment.yml** de la siguiente forma:
      ``` bash
      conda env create --file environment.yml
      conda activate web_scraping_env
      ```
   Este environment ya tiene especificada tanto la versiÃ³n de Python utilizada, como las librerÃ­as de las que depende. De esta forma, puedes saltarte el siguiente paso. 
   <br>

1. Si no usas Anaconda y/o no tienes instaladas las librerÃ­as usadas en el programa, usa:
      ``` bash
      pip install -r requirements.txt
      ```

## CÃ³mo ejecutar el proyecto?

El proyecto se ejecuta desde el script principal (``main.py``) a travÃ©s de consola. A continuaciÃ³n, se detallan las opciones de ejecuciÃ³n disponibles.

### 0.1. Listar las categorÃ­as disponibles

Para ver todas las categorÃ­as que se pueden seleccionar, utiliza el siguiente comando:

```bash
python main.py --list-categories
```
Este comando **solo muestra las categorÃ­as disponibles**.

### 0.2. Listar las subcategorÃ­as disponibles

Para ver todas las subcategorÃ­as que se pueden seleccionar de una categorÃ­a, utiliza el siguiente comando:

```bash
python main.py --category <NOMBRE_CATEGORÃA> --list-subcategories
```
Este comando **solo muestra las subcategorÃ­as disponibles** de una categorÃ­a dada.

> [!IMPORTANT]
> Para conocer quÃ© subcategorÃ­as hay disponibles, es necesario proporcionar una Ãºnica categorÃ­a. TambiÃ©n devolverÃ¡ error si se usa la opciÃ³n de "todas las categorÃ­as" (--category all).

### 1. Ejecutar el scraper en una categorÃ­a completa

Para ejecutar el scraper en una **categorÃ­a completa** (es decir, en todas sus subcategorÃ­as), usa:

```bash
python main.py --category <NOMBRE_CATEGORÃA>
```

Ejemplo:

```bash
python main.py --category Frescos
```

### 2. Ejecutar el scraper en subcategorÃ­as especÃ­ficas

Para ejecutar el scraper en **subcategorÃ­as especÃ­ficas**, usa:

```bash
python main.py --category <NOMBRE_CATEGORÃA> --subcategories <SUBCATEGORÃA_1> <SUBCATEGORÃA_2>
```

Ejemplo:

```bash
python main.py --category Frescos --subcategories "Fruites i verdura" "Xarcuteria"
```

De la misma forma tambiÃ©n se pueden ejecutar **varias categorÃ­as a la vez**, aunque en este caso **no se podrÃ¡n especificar subcategorÃ­as** especÃ­ficas de cada cateogorÃ­a.

### 3. Ejecutar el scraper en todas las categorÃ­as

Para ejecutar el scraper en **todas las categorÃ­as** disponible, usa:

```bash
python main.py --category all
```

Este comando ejecutarÃ¡ el scraper en todas las categorÃ­as y sus subcategorÃ­as.

> [!CAUTION]
>Si seleccionas la opciÃ³n de "todas las categorÃ­as" (`--category all`), utiliza el programa de forma responsable. Aunque el cÃ³digo implementa medidas para evitar la sobrecarga del servidor (como tiempos de espera), es importante moderar el uso para no saturar los recursos del sitio web de Bonpreu.

### 4. Fusionar CSVs exportados

Para **fusionar varios CSVs** exportados por categorÃ­as en un solo archivo CSV, usa:

```bash
python merge_csv.py
```

Ten en cuenta que este script identifica **todos los CSVs** presentes en la carpeta [data](/data) (con excepciÃ³n a posibles archivos fusionados anteriores) y junta todos los registros en un archivo resultante llamado ``bonpreu_products_YYYYmmdd_HHMMSS.csv``.

## DOI del dataset generado

El dataset generado estÃ¡ publicado en [Zenodo](https://zenodo.org/) con el tÃ­tulo: "".

[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.14036298.svg.svg)](https://doi.org/10.5281/zenodo.14036298)


## Colaboradores
Este repositorio ha sido desarrollado por:
- ğŸ‘¨â€ğŸ’» David RoldÃ¡n Puig
- ğŸ‘¨â€ğŸ’» Albert Gallego JimÃ©nez